  # Введение в нейронные сети              
Урок 5. Рекуррентные нейронные сети               
Попробуйте починить сеть по словам.                 
                                 
Попробуйте изменить параметры нейронной сети, генерирующей текст таким образом, чтобы добиться генерации как можно более осмысленного текста.                 
Пришлите лучший текст из получившихся и опишите предпринятые для его получения действия. Можно использовать текст другого произведения.
                 
# Предоставлен код для обучения и генерации текста с использованием различных моделей глубокого обучения, таких как SimpleRNN и LSTM, а также модели GPT-2 из библиотеки Transformers.

1. Обучение и генерация текста с помощью моделей на основе Keras:

 - Этот код сначала обучает модель на основе символьного уровня с использованием SimpleRNN. Затем он генерирует текст, используя эту обученную модель.
 - После этого мы используем LSTM модель для обучения на базе слов и генерации текста.

2. Обучение модели GPT-2 с использованием библиотеки Transformers:

 - Этот код также включает обучение модели GPT-2 на большом корпусе текста.
 - После обучения мы используем эту модель для генерации текста на основе заданной фразы.

# Для получения более осмысленного текста можно попробовать следующие подходы:

** - Увеличение размера вложенного слоя (embedding) для улучшения представления слов.
- Использование более глубокой архитектуры LSTM для более долгосрочного запоминания зависимостей в тексте.
- Увеличение количества нейронов в слоях LSTM для увеличения емкости модели.
- Использование Dropout для регуляризации и предотвращения переобучения. **
